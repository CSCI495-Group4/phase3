{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7417982,"sourceType":"datasetVersion","datasetId":4315395},{"sourceId":7763359,"sourceType":"datasetVersion","datasetId":4540583},{"sourceId":11452003,"sourceType":"datasetVersion","datasetId":7175320}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Initilize Environment","metadata":{}},{"cell_type":"markdown","source":"## Initial Kaggle Imports\nCommented out and will be deleted later.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:24:47.488098Z","iopub.execute_input":"2025-10-09T15:24:47.488708Z","iopub.status.idle":"2025-10-09T15:24:47.493495Z","shell.execute_reply.started":"2025-10-09T15:24:47.488667Z","shell.execute_reply":"2025-10-09T15:24:47.492368Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"## Specific Imports\nimports used for the specific model tasks","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\nimport timm\n\nimport pandas as pd\nimport numpy as np\nimport random\n\nimport sys\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:24:47.495473Z","iopub.execute_input":"2025-10-09T15:24:47.495834Z","iopub.status.idle":"2025-10-09T15:24:47.520476Z","shell.execute_reply.started":"2025-10-09T15:24:47.495809Z","shell.execute_reply":"2025-10-09T15:24:47.519312Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Dataset Setup","metadata":{}},{"cell_type":"code","source":"#Extremely simple data set class.\nclass OurDataSetA(Dataset):\n    def __init__(self, data_directory, transform=None):\n        self.data = ImageFolder(data_directory, transform=transform)\n\n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, at_index):\n        return self.data[at_index]\n\n    @property\n    def classes(self):\n        return self.data.classes\n#END CLASS\n\n#Strings of data directories\nstr_data_dir_train = '/kaggle/input/balanced-raf-db-dataset-7575-grayscale/train'\nstr_data_dir_valid = '/kaggle/input/balanced-raf-db-dataset-7575-grayscale/val'\nstr_data_dir_test  = '/kaggle/input/balanced-raf-db-dataset-7575-grayscale/test'\n\n#Transforms\ntransform_a = transforms.Compose([\n    transforms.ToTensor()\n])\n\n# Order matters: spatial ops (resize/flip) → photometric (color) → tensor/normalize\ntransform_b = transforms.Compose([\n    # Resize all images to a fixed size (H, W). Models expect consistent shapes.\n    transforms.Resize((base_size)),\n\n    # Randomly flip left-right with probability p.\n    # p=0.5 means ~50% of images flipped; improves robustness to mirror variations.\n    transforms.RandomHorizontalFlip(p=0.5),\n\n    # Slight brightness/contrast jitter to reduce overfitting.\n    # brightness=0.1 allows +/-10% brightness; contrast=0.1 allows +/-10% contrast.\n    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n\n    # Convert PIL Image (H, W, C) in [0, 255] to torch.Tensor (C, H, W) in [0.0, 1.0].\n    transforms.ToTensor(),\n\n    # Optional: Uncomment if using pretrained backbones (e.g., ResNet/EfficientNet on ImageNet)\n    # Scales channels to ImageNet mean/std: mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]\n    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n#Dataset variables\ndataset_train = OurDataSetA(str_data_dir_train, transform_a)\ndataset_valid = OurDataSetA(str_data_dir_valid, transform_a)\ndataset_test  = OurDataSetA(str_data_dir_test, transform_a)\n\n#Label Dictionary\nlabel_dict ={\n    0:\"Angry\",\n    1:\"Disgust\",\n    2:\"Fear\",\n    3:\"Happy\",\n    4:\"Neutral\",\n    5:\"Sad\",\n    6:\"Surprise\"\n}\n\n#This just serves to take a random snippet from the dataset and display it for demo purposes\nvar_rand = random.randint(1,(4289*7))\nimage, label = dataset_train[var_rand]\nprint(\"index used: \", var_rand)\nprint(label_dict[label])\nimage","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:24:47.521526Z","iopub.execute_input":"2025-10-09T15:24:47.521788Z","iopub.status.idle":"2025-10-09T15:25:07.428712Z","shell.execute_reply.started":"2025-10-09T15:24:47.521769Z","shell.execute_reply":"2025-10-09T15:25:07.427741Z"}},"outputs":[{"name":"stdout","text":"index used:  14829\nHappy\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"tensor([[[0.7059, 0.7255, 0.7490,  ..., 0.1216, 0.0863, 0.0549],\n         [0.7059, 0.7216, 0.7451,  ..., 0.1451, 0.1098, 0.0824],\n         [0.7020, 0.7216, 0.7451,  ..., 0.1804, 0.1451, 0.1176],\n         ...,\n         [0.0157, 0.2471, 0.5176,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0157, 0.1137, 0.2627,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0235, 0.0078, 0.0431,  ..., 0.0039, 0.0039, 0.0039]],\n\n        [[0.7059, 0.7255, 0.7490,  ..., 0.1216, 0.0863, 0.0549],\n         [0.7059, 0.7216, 0.7451,  ..., 0.1451, 0.1098, 0.0824],\n         [0.7020, 0.7216, 0.7451,  ..., 0.1804, 0.1451, 0.1176],\n         ...,\n         [0.0157, 0.2471, 0.5176,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0157, 0.1137, 0.2627,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0235, 0.0078, 0.0431,  ..., 0.0039, 0.0039, 0.0039]],\n\n        [[0.7059, 0.7255, 0.7490,  ..., 0.1216, 0.0863, 0.0549],\n         [0.7059, 0.7216, 0.7451,  ..., 0.1451, 0.1098, 0.0824],\n         [0.7020, 0.7216, 0.7451,  ..., 0.1804, 0.1451, 0.1176],\n         ...,\n         [0.0157, 0.2471, 0.5176,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0157, 0.1137, 0.2627,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0235, 0.0078, 0.0431,  ..., 0.0039, 0.0039, 0.0039]]])"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"# Data Loaders\nloading... loading... loading...","metadata":{}},{"cell_type":"code","source":"#These just make use of the pre-made class DataLoader so there's no need to define our own here\nloader_train = DataLoader(dataset_train, batch_size = 32, shuffle = True)\nloader_valid = DataLoader(dataset_valid, batch_size = 32, shuffle = False)\nloader_test  = DataLoader(dataset_test, batch_size = 32, shuffle = False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:25:07.429671Z","iopub.execute_input":"2025-10-09T15:25:07.430006Z","iopub.status.idle":"2025-10-09T15:25:07.439457Z","shell.execute_reply.started":"2025-10-09T15:25:07.429983Z","shell.execute_reply":"2025-10-09T15:25:07.437768Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Classifier\nthe model itself for simple tasks of classification.","metadata":{}},{"cell_type":"code","source":"class EmotionClassifier(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.base_model = timm.create_model('efficientnet_b0',pretrained=True) #Set base model\n        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n\n        enet_out_size = 1280\n        \n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(enet_out_size, num_classes)\n        )\n\n    def forward(self, x):\n        x = self.features(x)\n        output = self.classifier(x)\n        return output\n#END CLASS\n\n#Create the model, we'll call it model_one.\nmodel_one = EmotionClassifier(num_classes=7)\n\n#this is just done to show a snippet of the models layout.\nprint(str(model_one)[:300])\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:25:07.442598Z","iopub.execute_input":"2025-10-09T15:25:07.442967Z","iopub.status.idle":"2025-10-09T15:25:07.795860Z","shell.execute_reply.started":"2025-10-09T15:25:07.442936Z","shell.execute_reply":"2025-10-09T15:25:07.794090Z"}},"outputs":[{"name":"stdout","text":"EmotionClassifier(\n  (base_model): EfficientNet(\n    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn1): BatchNormAct2d(\n      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Training\nQueue eye of the tiger","metadata":{}},{"cell_type":"code","source":"#Set up for the loop\n# Loss Function\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer\noptimizer = optim.Adam(model_one.parameters(), lr=0.001)\n\n# Length in Epochs\nnumber_of_epochs = 5\n\n# Losses Arrays\ntraining_losses = []\nvalidation_losses = []\n\n# Establish Device settings\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Move model to device\nmodel_one.to(device) #model_one is made in the Classifier segment\nprint('--') #Kaggle really really wants to put things so if I don't give it this it outputs the entire layout of the model below, and its a lot of text man.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:25:07.796984Z","iopub.execute_input":"2025-10-09T15:25:07.797318Z","iopub.status.idle":"2025-10-09T15:25:07.813220Z","shell.execute_reply.started":"2025-10-09T15:25:07.797293Z","shell.execute_reply":"2025-10-09T15:25:07.812138Z"}},"outputs":[{"name":"stdout","text":"--\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#The actual loop\nfor epoch in range(number_of_epochs):\n    #Training Phase\n    model_one.train() #Signal to the model that we're training\n    running_loss = 0.0 #Current loss of the session\n    for images, labels in tqdm(loader_train, desc='Training Phase'): #\n        # Move images and labels to the device\n        images = images.to(device)\n        labels = labels.to(device)\n\n        #\n        optimizer.zero_grad()\n        outputs = model_one(images)##\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * labels.size(0)\n        \n    # Loss Tracking\n    train_loss = running_loss / len(loader_train.dataset)\n    training_losses.append(train_loss)\n    \n    #Validation Phase\n    model_one.eval() #Signal to the model that we're not training.\n    running_loss = 0.0\n    with torch.no_grad():\n        for images, labels in tqdm(loader_valid, desc='Validation loop'):\n            # Move inputs and labels to the device\n            images = images.to(device)\n            labels = labels.to(device)\n\n            #\n            outputs = model_one(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * labels.size(0)\n\n    # Loss Tracking\n    valid_loss = running_loss / len(loader_valid.dataset)\n    validation_losses.append(valid_loss)\n    print(f\"Epoch {epoch+1}/{number_of_epochs} - Train loss: {train_loss}, Validation loss: {valid_loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-09T15:25:07.814286Z","iopub.execute_input":"2025-10-09T15:25:07.814605Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Training Phase:   0%|          | 0/939 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86fa3f629acc4145a2109963d5d45acd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation loop:   0%|          | 0/235 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a9a9cee29b74f3f8130df561140b972"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/5 - Train loss: 0.8672749136034472, Validation loss: 0.5158027584301129\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training Phase:   0%|          | 0/939 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83dce76ca65d4f52b291cffa105a4d02"}},"metadata":{}}],"execution_count":null}]}